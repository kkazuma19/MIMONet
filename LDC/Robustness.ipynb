{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc3adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "from utils import MIMONetDataset, DeepONetDataset, ChannelScaler\n",
    "from mimonet_drop import MIMONet_Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53ff8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cb7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = \"/projects/bcnx/kazumak2/MIMONet/LDC/\"\n",
    "data_dir = os.path.join(working_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e440f5",
   "metadata": {},
   "source": [
    "## Load datasets and set dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2890022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_branch shape: (3949, 90)\n",
      "train_target shape: (3949, 4225, 3)\n",
      "branch input min: -0.953423\n",
      "branch input max: 13.645064\n",
      "test_branch shape: (988, 90)\n",
      "test_target shape: (988, 4225, 3)\n"
     ]
    }
   ],
   "source": [
    "# trunk dataset\n",
    "trunk_input = np.load(os.path.join(data_dir, \"share/coords.npy\"))\n",
    "\n",
    "# training data\n",
    "train_branch = np.load(os.path.join(data_dir, \"training/train_branch_input.npy\"))\n",
    "\n",
    "# [samples, channel, gridpoints]\n",
    "train_target = np.load(os.path.join(data_dir, \"training/train_target.npy\"))\n",
    "\n",
    "\n",
    "print(\"train_branch shape:\", train_branch.shape)\n",
    "print(\"train_target shape:\", train_target.shape)\n",
    "\n",
    "# scaling the train_branch data [min-max scaling]\n",
    "b_max = np.max(train_branch)\n",
    "b_min = np.min(train_branch)\n",
    "\n",
    "train_branch = 2 * (train_branch - b_min) / (b_max - b_min) - 1\n",
    "\n",
    "print('branch input min:', b_min)\n",
    "print('branch input max:', b_max)\n",
    "\n",
    "test_branch = np.load(os.path.join(data_dir, \"test/test_branch_input.npy\"))\n",
    "\n",
    "test_target = np.load(os.path.join(data_dir, \"test/test_target.npy\"))\n",
    "\n",
    "print(\"test_branch shape:\", test_branch.shape)\n",
    "print(\"test_target shape:\", test_target.shape)\n",
    "\n",
    "# scaling the test_branch data [min-max scaling]\n",
    "test_branch = 2 * (test_branch - b_min) / (b_max - b_min) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f9d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the target data\n",
    "'''  \n",
    "note: reverse the scaling for the target data\n",
    "train_target = scaler.inverse_transform(train_target_scaled)\n",
    "test_target = scaler.inverse_transform(test_target_scaled)\n",
    "'''\n",
    "scaler = ChannelScaler(method='minmax', feature_range=(-1, 1))\n",
    "scaler.fit(train_target)\n",
    "train_target_scaled = scaler.transform(train_target)\n",
    "test_target_scaled = scaler.transform(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf8820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "test_dataset = MIMONetDataset(\n",
    "    [test_branch],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    test_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13343e92",
   "metadata": {},
   "source": [
    "## Initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f17597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1,032,963\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "dim = 256\n",
    "branch_input_dim1 = 90\n",
    "branch_input_dim2 = 2\n",
    "trunk_input_dim = 2\n",
    "\n",
    "# Define MIONet instance (no Fourier, no final linear)\n",
    "model_args = {\n",
    "    'branch_arch_list': [\n",
    "        [branch_input_dim1, 512, 512, 512, dim],\n",
    "        # [branch_input_dim2, 512, 512, 512, dim]\n",
    "    ],\n",
    "    'trunk_arch': [trunk_input_dim, 256, 256, 256, dim],\n",
    "    'num_outputs': 3,  # number of output channels\n",
    "    'activation_fn': nn.ReLU,\n",
    "    'merge_type': 'mul',\n",
    "    'dropout_p': 0.1\n",
    "}\n",
    "    \n",
    "\n",
    "model = MIMONet_Drop(\n",
    "    **model_args\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Print parameter count\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa9dcf",
   "metadata": {},
   "source": [
    "## UQ with MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34ded643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "N = 20  # Number of ensemble members\n",
    "ensemble = []\n",
    "\n",
    "for _ in range(N):\n",
    "    m = MIMONet_Drop(**model_args)\n",
    "    m.load_state_dict(torch.load('LDC/checkpoints/best_model_dropout.pt'))\n",
    "    m.to(device)\n",
    "    m.train()  # Enable dropout during inference\n",
    "    ensemble.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ac7c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get predictions from all models in the ensemble\n",
    "def ensemble_predict(ensemble, branch_batch, trunk_batch):\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for m in ensemble:\n",
    "            preds.append(m(branch_batch, trunk_batch).cpu().numpy())\n",
    "    return np.stack(preds, axis=0)  # shape: (N, batch_size, ...)\n",
    "\n",
    "def get_ensemble_predictions(ensemble, data_loader, device=device):\n",
    "\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "\n",
    "    # Set all models to evaluation mode\n",
    "    \n",
    "    for i, (branch_data, trunk_data, target_data) in enumerate(data_loader):\n",
    "        branch_data = [bd.to(device).float() for bd in branch_data]\n",
    "        trunk_data = trunk_data.to(device).float()\n",
    "        target_data = target_data.to(device).float()\n",
    "\n",
    "        # Predict from ensemble: returns shape (E, batch_size, ...)\n",
    "        preds = ensemble_predict(ensemble, branch_data, trunk_data)\n",
    "        all_preds.append(preds)  # Collect each batchâ€™s ensemble predictions\n",
    "        all_targets.append(target_data.cpu().numpy())\n",
    "\n",
    "    # Concatenate across batches\n",
    "    all_preds = np.concatenate(all_preds, axis=1)  # [E, total_samples, ...]\n",
    "    all_targets = np.concatenate(all_targets, axis=0)  # [total_samples, ...]\n",
    "\n",
    "    print('Shape of all_preds:', all_preds.shape)\n",
    "\n",
    "    return all_preds, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57f5b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all_preds: (20, 988, 4225, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get ensemble predictions on test set\n",
    "ensemble_preds, all_targets = get_ensemble_predictions(ensemble, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6fa511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and stddev across ensemble members\n",
    "mean_preds = np.mean(ensemble_preds, axis=0)  # [total_samples, ...]\n",
    "stddev_preds = np.std(ensemble_preds, axis=0)  # [total_samples, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50e421a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse scaling the predictions\n",
    "mean_preds_rescaled = scaler.inverse_transform(mean_preds)\n",
    "stddev_preds_rescaled = scaler.inverse_transform(stddev_preds)\n",
    "all_targets_rescaled = scaler.inverse_transform(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f89fd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean relative L2 error (channel 0): 0.0396\n",
      "Mean relative L2 error (channel 1): 0.0724\n",
      "Mean relative L2 error (channel 2): 0.0479\n"
     ]
    }
   ],
   "source": [
    "# compute mean relative l2 error per output channel\n",
    "mean_l2_0 = np.mean(np.linalg.norm(mean_preds_rescaled[..., 0] - all_targets_rescaled[..., 0], axis=1) / np.linalg.norm(all_targets_rescaled[..., 0], axis=1))\n",
    "mean_l2_1 = np.mean(np.linalg.norm(mean_preds_rescaled[..., 1] - all_targets_rescaled[..., 1], axis=1) / np.linalg.norm(all_targets_rescaled[..., 1], axis=1))\n",
    "mean_l2_2 = np.mean(np.linalg.norm(mean_preds_rescaled[..., 2] - all_targets_rescaled[..., 2], axis=1) / np.linalg.norm(all_targets_rescaled[..., 2], axis=1))\n",
    "print(f\"Mean relative L2 error (channel 0): {mean_l2_0:.4f}\")\n",
    "print(f\"Mean relative L2 error (channel 1): {mean_l2_1:.4f}\")\n",
    "print(f\"Mean relative L2 error (channel 2): {mean_l2_2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch-env]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-env-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
