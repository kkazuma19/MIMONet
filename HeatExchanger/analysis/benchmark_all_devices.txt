

==================================================
Device name: NVIDIA A100-SXM4-40GB
Mean latency per inference: 11.596 ± 2.909 ms
Throughput: 86.2 ± 21.6 samples/s
Average Power: 217.84 ± 54.96 W
Energy per inference: 2.546 ± 0.971 J
Peak VRAM usage: 2543.7 MB (mean 2543.7 ± 0.0)

==================================================
Device name: NVIDIA A40
Mean latency per inference: 14.141 ± 2.419 ms
Throughput: 70.7 ± 12.1 samples/s
Average Power: 134.86 ± 37.46 W
Energy per inference: 1.918 ± 0.657 J
Peak VRAM usage: 2379.4 MB (mean 2379.4 ± 0.0)

==================================================
Device name: NVIDIA H200
Mean latency per inference: 4.948 ± 3.242 ms
Throughput: 202.1 ± 132.4 samples/s
Average Power: 159.00 ± 24.62 W
Energy per inference: 0.798 ± 0.628 J
Peak VRAM usage: 3003.4 MB (mean 3003.4 ± 0.0)


==================================================
Device name: NVIDIA GH200 120GB
Mean latency per inference: 4.307 ± 2.852 ms
Throughput: 232.2 ± 153.8 samples/s
Average Power: 177.11 ± 19.15 W
Energy per inference: 0.778 ± 0.637 J
Peak VRAM usage: 3451.3 MB (mean 3450.3 ± 0.3)