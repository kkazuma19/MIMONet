{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c19563cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "from utils import MIMONetDataset, DeepONetDataset, ChannelScaler\n",
    "from mimonet import MIMONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68626d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcf3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = \"/projects/bcnx/kazumak2/MIMONet/Subchannel/\"\n",
    "data_dir = os.path.join(working_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c3cb8",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662230f",
   "metadata": {},
   "source": [
    "### Load sharing parameters/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e26d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunk dataset\n",
    "trunk_input = np.load(os.path.join(data_dir, \"share/trunk_input.npz\"))['trunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab5c36",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a28faea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_branch_1 shape: (4000, 100)\n",
      "train_branch_2 shape: (4000, 2)\n",
      "train_target shape: (4000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "train_branch = np.load(os.path.join(data_dir, \"training/train_branch_input.npz\"))\n",
    "train_branch_1 = train_branch['func_params']\n",
    "train_branch_2 = train_branch['stat_params']\n",
    "\n",
    "# [samples, channel, gridpoints]\n",
    "train_target = np.load(os.path.join(data_dir, \"training/train_target.npz\"))['target']\n",
    "# convert to [samples, gridpoints, channel]\n",
    "train_target = np.moveaxis(train_target, 1, 2)\n",
    "\n",
    "print(\"train_branch_1 shape:\", train_branch_1.shape)\n",
    "print(\"train_branch_2 shape:\", train_branch_2.shape)\n",
    "print(\"train_target shape:\", train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc288a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the functional input data using predefined mean and std\n",
    "f_mean = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['mean']\n",
    "f_std = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['std']\n",
    "\n",
    "train_branch_1 = (train_branch_1 - f_mean) / f_std\n",
    "\n",
    "# scaling the static input data using predefined mean and std\n",
    "s_mean = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['mean']\n",
    "s_std = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['std']\n",
    "\n",
    "for i in range(s_mean.shape[0]):\n",
    "    train_branch_2[:, i] = (train_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88f645",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54556d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_branch_1 shape: (1000, 100)\n",
      "test_branch_2 shape: (1000, 2)\n",
      "test_target shape: (1000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "test_branch = np.load(os.path.join(data_dir, \"test/test_branch_input.npz\"))\n",
    "test_branch_1 = test_branch['func_params']\n",
    "test_branch_2 = test_branch['stat_params']\n",
    "\n",
    "test_target = np.load(os.path.join(data_dir, \"test/test_target.npz\"))['target']\n",
    "test_target = np.moveaxis(test_target, 1, 2)\n",
    "\n",
    "print(\"test_branch_1 shape:\", test_branch_1.shape)\n",
    "print(\"test_branch_2 shape:\", test_branch_2.shape)\n",
    "print(\"test_target shape:\", test_target.shape)\n",
    "\n",
    "# scaling the functional input data using predefined mean and std\n",
    "test_branch_1 = (test_branch_1 - f_mean) / f_std\n",
    "# scaling the static input data using predefined mean and std\n",
    "for i in range(s_mean.shape[0]):\n",
    "    test_branch_2[:, i] = (test_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dddd92",
   "metadata": {},
   "source": [
    "### Scaling the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "688e7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the target data\n",
    "'''  \n",
    "note: reverse the scaling for the target data\n",
    "train_target = scaler.inverse_transform(train_target_scaled)\n",
    "test_target = scaler.inverse_transform(test_target_scaled)\n",
    "'''\n",
    "scaler = ChannelScaler(method='minmax', feature_range=(-1, 1))\n",
    "scaler.fit(train_target)\n",
    "train_target_scaled = scaler.transform(train_target)\n",
    "test_target_scaled = scaler.transform(test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87ae6a",
   "metadata": {},
   "source": [
    "## Torch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf71b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "test_dataset = MIMONetDataset(\n",
    "    [test_branch_1, test_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    test_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a754121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MIMONetDataset(\n",
    "    [train_branch_1, train_branch_2],  # branch_data_list\n",
    "    trunk_input,                       # trunk_data\n",
    "    train_target_scaled                # target_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b2674",
   "metadata": {},
   "source": [
    "## MIMONet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57223d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1,630,467\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "dim = 256\n",
    "branch_input_dim1 = 100\n",
    "branch_input_dim2 = 2\n",
    "trunk_input_dim = 2\n",
    "\n",
    "# Define MIONet instance (no Fourier, no final linear)\n",
    "model = MIMONet(\n",
    "    branch_arch_list=[\n",
    "        [branch_input_dim1, 512, 512, 512, dim],\n",
    "        [branch_input_dim2, 512, 512, 512, dim]\n",
    "    ],\n",
    "    trunk_arch=[trunk_input_dim, 256, 256, dim],\n",
    "    num_outputs=3, \n",
    "    activation_fn=nn.ReLU,\n",
    "    merge_type='mul'  # or 'sum'\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Print parameter count\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eadbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae939d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1E-6)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fad6d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "Epoch 1, LR: 1.00e-03, Train Loss: 0.200536, Val Loss: 0.188035\n",
      "Epoch 2, LR: 1.00e-03, Train Loss: 0.188936, Val Loss: 0.185007\n",
      "Epoch 3, LR: 1.00e-03, Train Loss: 0.187174, Val Loss: 0.188085\n",
      "Epoch 4, LR: 1.00e-03, Train Loss: 0.189568, Val Loss: 0.187934\n",
      "Epoch 5, LR: 1.00e-03, Train Loss: 0.189350, Val Loss: 0.189042\n",
      "\n",
      "=== Fold 2/5 ===\n",
      "Epoch 1, LR: 1.00e-03, Train Loss: 0.189022, Val Loss: 0.189470\n",
      "Epoch 2, LR: 1.00e-03, Train Loss: 0.188709, Val Loss: 0.189222\n",
      "Epoch 3, LR: 1.00e-03, Train Loss: 0.188983, Val Loss: 0.190389\n",
      "Epoch 4, LR: 1.00e-03, Train Loss: 0.188927, Val Loss: 0.188978\n",
      "Epoch 5, LR: 1.00e-03, Train Loss: 0.188809, Val Loss: 0.189154\n",
      "\n",
      "=== Fold 3/5 ===\n",
      "Epoch 1, LR: 1.00e-03, Train Loss: 0.188894, Val Loss: 0.188196\n",
      "Epoch 2, LR: 1.00e-03, Train Loss: 0.188837, Val Loss: 0.187875\n",
      "Epoch 3, LR: 1.00e-03, Train Loss: 0.188765, Val Loss: 0.190390\n",
      "Epoch 4, LR: 1.00e-03, Train Loss: 0.188896, Val Loss: 0.187877\n",
      "Epoch 5, LR: 1.00e-03, Train Loss: 0.188712, Val Loss: 0.187948\n",
      "\n",
      "=== Fold 4/5 ===\n",
      "Epoch 1, LR: 1.00e-03, Train Loss: 0.188395, Val Loss: 0.194452\n",
      "Epoch 2, LR: 1.00e-03, Train Loss: 0.188416, Val Loss: 0.189555\n",
      "Epoch 3, LR: 1.00e-03, Train Loss: 0.188261, Val Loss: 0.190063\n",
      "Epoch 4, LR: 1.00e-03, Train Loss: 0.188295, Val Loss: 0.191071\n",
      "Epoch 5, LR: 1.00e-03, Train Loss: 0.188347, Val Loss: 0.190911\n",
      "\n",
      "=== Fold 5/5 ===\n",
      "Epoch 1, LR: 1.00e-03, Train Loss: 0.189066, Val Loss: 0.187035\n",
      "Epoch 2, LR: 1.00e-03, Train Loss: 0.188922, Val Loss: 0.187996\n",
      "Epoch 3, LR: 1.00e-03, Train Loss: 0.188934, Val Loss: 0.187669\n",
      "Epoch 4, LR: 1.00e-03, Train Loss: 0.188999, Val Loss: 0.186791\n",
      "Epoch 5, LR: 1.00e-03, Train Loss: 0.188878, Val Loss: 0.187143\n",
      "\n",
      "=== K-Fold Cross-Validation Results ===\n",
      "Best Validation Loss for each fold: [0.18500665277242662, 0.18897826239466667, 0.18787478767335414, 0.18955548837780953, 0.18679050989449025]\n",
      "\n",
      "CV Results: Mean=0.187641, Std=0.001623\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "''' \n",
    "train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset,\n",
    "    device='cuda',\n",
    "    num_epochs=100,\n",
    "    batch_size=4,\n",
    "    lr=1e-3,\n",
    "    patience=20,\n",
    "    multi_gpu=False,\n",
    "    working_dir=\"Subchannel\",   \n",
    ")\n",
    "'''\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = None,\n",
    "    device='cuda',\n",
    "    num_epochs=5,\n",
    "    batch_size=4,\n",
    "    criterion= criterion,\n",
    "    patience=1000,\n",
    "    k_fold=5,\n",
    "    multi_gpu=False,\n",
    "    working_dir=\"\"\n",
    ")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336eb58",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da294b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model 0 not found. Please check the path.\n",
      "Best model 1 not found. Please check the path.\n",
      "Best model 2 not found. Please check the path.\n",
      "Best model 3 not found. Please check the path.\n",
      "Best model 4 not found. Please check the path.\n"
     ]
    }
   ],
   "source": [
    "train_mode = 'k_fold'\n",
    "n_hold = 5\n",
    "\n",
    "if train_mode == 'k_fold':\n",
    "    for i in range(n_hold):\n",
    "        best_model_path = os.path.join(working_dir, f\"checkpoints/best_model_fold{i+1}.pt\")\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            print(f\"Best model for fold {i+1} loaded.\")\n",
    "        else:\n",
    "            print(f\"Best model for fold {i+1} not found. Please check the path.\")\n",
    "            exit(1)\n",
    "        \n",
    "        test_kfold_model(fold_id=i+1)  # Call test with the current fold ID\n",
    "    \n",
    "else:\n",
    "    # Load the best model (best_model.pt)\n",
    "    best_model_path = os.path.join(working_dir, \"checkpoints/best_model.pt\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(\"Best model loaded.\")\n",
    "    else:\n",
    "        print(\"Best model not found. Please check the path.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Test the model\n",
    "    test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd9b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch-env]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
