{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19563cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "from utils import MIMONetDataset, DeepONetDataset, ChannelScaler\n",
    "from mimonet import MIMONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68626d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcf3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = \"/projects/bcnx/kazumak2/MIMONet/Subchannel/\"\n",
    "data_dir = os.path.join(working_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c3cb8",
   "metadata": {},
   "source": [
    "## load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662230f",
   "metadata": {},
   "source": [
    "### Load sharing parameters/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e26d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trunk dataset\n",
    "trunk_input = np.load(os.path.join(data_dir, \"share/trunk_input.npz\"))['trunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab5c36",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a28faea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_branch_1 shape: (4000, 100)\n",
      "train_branch_2 shape: (4000, 2)\n",
      "train_target shape: (4000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "train_branch = np.load(os.path.join(data_dir, \"training/train_branch_input.npz\"))\n",
    "train_branch_1 = train_branch['func_params']\n",
    "train_branch_2 = train_branch['stat_params']\n",
    "\n",
    "# [samples, channel, gridpoints]\n",
    "train_target = np.load(os.path.join(data_dir, \"training/train_target.npz\"))['target']\n",
    "# convert to [samples, gridpoints, channel]\n",
    "train_target = np.moveaxis(train_target, 1, 2)\n",
    "\n",
    "print(\"train_branch_1 shape:\", train_branch_1.shape)\n",
    "print(\"train_branch_2 shape:\", train_branch_2.shape)\n",
    "print(\"train_target shape:\", train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dc288a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the functional input data using predefined mean and std\n",
    "f_mean = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['mean']\n",
    "f_std = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['std']\n",
    "\n",
    "train_branch_1 = (train_branch_1 - f_mean) / f_std\n",
    "\n",
    "# scaling the static input data using predefined mean and std\n",
    "s_mean = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['mean']\n",
    "s_std = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['std']\n",
    "\n",
    "for i in range(s_mean.shape[0]):\n",
    "    train_branch_2[:, i] = (train_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88f645",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54556d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_branch_1 shape: (1000, 100)\n",
      "test_branch_2 shape: (1000, 2)\n",
      "test_target shape: (1000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "test_branch = np.load(os.path.join(data_dir, \"test/test_branch_input.npz\"))\n",
    "test_branch_1 = test_branch['func_params']\n",
    "test_branch_2 = test_branch['stat_params']\n",
    "\n",
    "test_target = np.load(os.path.join(data_dir, \"test/test_target.npz\"))['target']\n",
    "test_target = np.moveaxis(test_target, 1, 2)\n",
    "\n",
    "print(\"test_branch_1 shape:\", test_branch_1.shape)\n",
    "print(\"test_branch_2 shape:\", test_branch_2.shape)\n",
    "print(\"test_target shape:\", test_target.shape)\n",
    "\n",
    "# scaling the functional input data using predefined mean and std\n",
    "test_branch_1 = (test_branch_1 - f_mean) / f_std\n",
    "# scaling the static input data using predefined mean and std\n",
    "for i in range(s_mean.shape[0]):\n",
    "    test_branch_2[:, i] = (test_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dddd92",
   "metadata": {},
   "source": [
    "### Scaling the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688e7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the target data\n",
    "'''  \n",
    "note: reverse the scaling for the target data\n",
    "train_target = scaler.inverse_transform(train_target_scaled)\n",
    "test_target = scaler.inverse_transform(test_target_scaled)\n",
    "'''\n",
    "scaler = ChannelScaler(method='minmax', feature_range=(-1, 1))\n",
    "scaler.fit(train_target)\n",
    "train_target_scaled = scaler.transform(train_target)\n",
    "test_target_scaled = scaler.transform(test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87ae6a",
   "metadata": {},
   "source": [
    "## Torch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf71b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "test_dataset = MIMONetDataset(\n",
    "    [test_branch_1, test_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    test_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a754121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MIMONetDataset(\n",
    "    [train_branch_1, train_branch_2],  # branch_data_list\n",
    "    trunk_input,                       # trunk_data\n",
    "    train_target_scaled                # target_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b2674",
   "metadata": {},
   "source": [
    "## MIMONet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57223d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1,696,259\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "dim = 256\n",
    "branch_input_dim1 = 100\n",
    "branch_input_dim2 = 2\n",
    "trunk_input_dim = 2\n",
    "\n",
    "# Define MIONet instance (no Fourier, no final linear)\n",
    "model = MIMONet(\n",
    "    branch_arch_list=[\n",
    "        [branch_input_dim1, 512, 512, 512, dim],\n",
    "        [branch_input_dim2, 512, 512, 512, dim]\n",
    "    ],\n",
    "    trunk_arch=[trunk_input_dim, 256, 256, 256, dim],\n",
    "    num_outputs=3, \n",
    "    activation_fn=nn.ReLU,\n",
    "    merge_type='mul'  # or 'sum'\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Print parameter count\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eadbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae939d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1E-6)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "''' \n",
    "train_model(\n",
    "    model=model,\n",
    "    dataset=train_dataset,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = None,\n",
    "    device='cuda',\n",
    "    num_epochs=5,\n",
    "    batch_size=4,\n",
    "    criterion= criterion,\n",
    "    patience=1000,\n",
    "    k_fold=5,\n",
    "    multi_gpu=False,\n",
    "    working_dir=\"\"\n",
    ")\n",
    "'''\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336eb58",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7602388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import test_kfold_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2da294b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for fold 1 loaded.\n",
      "Mean relative L2 errors: [0.08067496 0.00322554 0.06602502]\n",
      "Standard deviation of relative L2 errors: [0.00085585 0.00086175 0.00069564]\n",
      "Best model for fold 2 loaded.\n",
      "Mean relative L2 errors: [0.08369818 0.00428187 0.07606768]\n",
      "Standard deviation of relative L2 errors: [0.00100787 0.00147104 0.00078902]\n",
      "Best model for fold 3 loaded.\n",
      "Mean relative L2 errors: [0.06665401 0.00285575 0.05448814]\n",
      "Standard deviation of relative L2 errors: [0.0003883  0.00087991 0.00051551]\n",
      "Best model for fold 4 loaded.\n",
      "Mean relative L2 errors: [0.15695732 0.00465049 0.09746448]\n",
      "Standard deviation of relative L2 errors: [0.00054871 0.00050717 0.00284726]\n",
      "Best model for fold 5 loaded.\n",
      "Mean relative L2 errors: [0.24503203 0.00877593 0.38087257]\n",
      "Standard deviation of relative L2 errors: [0.00063114 0.00344348 0.00393621]\n"
     ]
    }
   ],
   "source": [
    "train_mode = 'k_fold'\n",
    "n_hold = 5\n",
    "\n",
    "if train_mode == 'k_fold':\n",
    "    for i in range(n_hold):\n",
    "        best_model_path = os.path.join(working_dir, f\"checkpoints/best_model_fold{i+1}.pt\")\n",
    "        \n",
    "        if os.path.exists(best_model_path):\n",
    "            model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            print(f\"Best model for fold {i+1} loaded.\")\n",
    "        else:\n",
    "            print(f\"Best model for fold {i+1} not found. Please check the path.\")\n",
    "            exit(1)\n",
    "        \n",
    "        test_kfold_model(\n",
    "            fold_id=i+1,\n",
    "            model=model,\n",
    "            test_loader=test_loader,\n",
    "            scaler=scaler,\n",
    "            working_dir=working_dir,\n",
    "            device=device,\n",
    "            test_branch=test_branch,\n",
    "            save_array=False\n",
    "        )   \n",
    "    \n",
    "else:\n",
    "    # Load the best model (best_model.pt)\n",
    "    best_model_path = os.path.join(working_dir, \"checkpoints/best_model.pt\")\n",
    "    if os.path.exists(best_model_path):\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        print(\"Best model loaded.\")\n",
    "    else:\n",
    "        print(\"Best model not found. Please check the path.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Test the model\n",
    "    #test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd9b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch-env]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
