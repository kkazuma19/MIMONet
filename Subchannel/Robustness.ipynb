{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe8cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    \n",
    "from utils import MIMONetDataset, DeepONetDataset, ChannelScaler\n",
    "from mimonet_drop import MIMONet_Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56785d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0882fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "working_dir = \"/projects/bcnx/kazumak2/MIMONet/Subchannel/\"\n",
    "data_dir = os.path.join(working_dir, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd122ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_branch_1 shape: (4000, 100)\n",
      "train_branch_2 shape: (4000, 2)\n",
      "train_target shape: (4000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "# trunk dataset\n",
    "trunk_input = np.load(os.path.join(data_dir, \"share/trunk_input.npz\"))['trunk']\n",
    "\n",
    "# training data\n",
    "train_branch = np.load(os.path.join(data_dir, \"training/train_branch_input.npz\"))\n",
    "train_branch_1 = train_branch['func_params']\n",
    "train_branch_2 = train_branch['stat_params']\n",
    "\n",
    "# [samples, channel, gridpoints]\n",
    "train_target = np.load(os.path.join(data_dir, \"training/train_target.npz\"))['target']\n",
    "# convert to [samples, gridpoints, channel]\n",
    "train_target = np.moveaxis(train_target, 1, 2)\n",
    "\n",
    "print(\"train_branch_1 shape:\", train_branch_1.shape)\n",
    "print(\"train_branch_2 shape:\", train_branch_2.shape)\n",
    "print(\"train_target shape:\", train_target.shape)\n",
    "\n",
    "# scaling the functional input data using predefined mean and std\n",
    "f_mean = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['mean']\n",
    "f_std = np.load(os.path.join(data_dir, \"share/func_mean_std_params.npz\"))['std']\n",
    "\n",
    "train_branch_1 = (train_branch_1 - f_mean) / f_std\n",
    "\n",
    "# scaling the static input data using predefined mean and std\n",
    "s_mean = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['mean']\n",
    "s_std = np.load(os.path.join(data_dir, \"share/stat_mean_std_params.npz\"))['std']\n",
    "\n",
    "for i in range(s_mean.shape[0]):\n",
    "    train_branch_2[:, i] = (train_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e70a666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_branch_1 shape: (1000, 100)\n",
      "test_branch_2 shape: (1000, 2)\n",
      "test_target shape: (1000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "test_branch = np.load(os.path.join(data_dir, \"test/test_branch_input.npz\"))\n",
    "test_branch_1 = test_branch['func_params']\n",
    "test_branch_2 = test_branch['stat_params']\n",
    "\n",
    "test_target = np.load(os.path.join(data_dir, \"test/test_target.npz\"))['target']\n",
    "test_target = np.moveaxis(test_target, 1, 2)\n",
    "\n",
    "print(\"test_branch_1 shape:\", test_branch_1.shape)\n",
    "print(\"test_branch_2 shape:\", test_branch_2.shape)\n",
    "print(\"test_target shape:\", test_target.shape)\n",
    "\n",
    "# scaling the functional input data using predefined mean and std\n",
    "test_branch_1 = (test_branch_1 - f_mean) / f_std\n",
    "# scaling the static input data using predefined mean and std\n",
    "for i in range(s_mean.shape[0]):\n",
    "    test_branch_2[:, i] = (test_branch_2[:, i] - s_mean[i]) / s_std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a5b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the target data\n",
    "'''  \n",
    "note: reverse the scaling for the target data\n",
    "train_target = scaler.inverse_transform(train_target_scaled)\n",
    "test_target = scaler.inverse_transform(test_target_scaled)\n",
    "'''\n",
    "scaler = ChannelScaler(method='minmax', feature_range=(-1, 1))\n",
    "scaler.fit(train_target)\n",
    "train_target_scaled = scaler.transform(train_target)\n",
    "test_target_scaled = scaler.transform(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28eec293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and dataloader\n",
    "test_dataset = MIMONetDataset(\n",
    "    [test_branch_1, test_branch_2],  # branch_data_list\n",
    "    trunk_input,                     # trunk_data\n",
    "    test_target_scaled               # target_data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,  # set to 1 for testing\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2167f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MIMONetDataset(\n",
    "    [train_branch_1, train_branch_2],  # branch_data_list\n",
    "    trunk_input,                       # trunk_data\n",
    "    train_target_scaled                # target_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89924fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1,696,259\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "dim = 256\n",
    "branch_input_dim1 = 100\n",
    "branch_input_dim2 = 2\n",
    "trunk_input_dim = 2\n",
    "\n",
    "model_args = {\n",
    "    'branch_arch_list': [\n",
    "        [branch_input_dim1, 512, 512, 512, dim],\n",
    "        [branch_input_dim2, 512, 512, 512, dim]\n",
    "    ],\n",
    "    'trunk_arch': [trunk_input_dim, 256, 256, 256, dim],\n",
    "    'num_outputs': 3,\n",
    "    'activation_fn': nn.ReLU,\n",
    "    'merge_type': 'mul',\n",
    "    'dropout_p': 0.1  # Dropout rate\n",
    "}\n",
    "\n",
    "model = MIMONet_Drop(**model_args)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print parameter count\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645a1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "N = 20  # Number of ensemble members\n",
    "ensemble = []\n",
    "\n",
    "for _ in range(N):\n",
    "    m = MIMONet_Drop(**model_args)\n",
    "    m.load_state_dict(torch.load('Subchannel/checkpoints/best_model_dropout.pt'))\n",
    "    m.to(device)\n",
    "    m.train()  # Enable dropout during inference\n",
    "    ensemble.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c7e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get predictions from all models in the ensemble\n",
    "def ensemble_predict(ensemble, branch_batch, trunk_batch):\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for m in ensemble:\n",
    "            preds.append(m(branch_batch, trunk_batch).cpu().numpy())\n",
    "    return np.stack(preds, axis=0)  # shape: (N, batch_size, ...)\n",
    "\n",
    "def get_ensemble_predictions(ensemble, data_loader, device=device):\n",
    "\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "\n",
    "    # Set all models to evaluation mode\n",
    "    \n",
    "    for i, (branch_data, trunk_data, target_data) in enumerate(data_loader):\n",
    "        branch_data = [bd.to(device).float() for bd in branch_data]\n",
    "        trunk_data = trunk_data.to(device).float()\n",
    "        target_data = target_data.to(device).float()\n",
    "\n",
    "        # Predict from ensemble: returns shape (E, batch_size, ...)\n",
    "        preds = ensemble_predict(ensemble, branch_data, trunk_data)\n",
    "        all_preds.append(preds)  # Collect each batchâ€™s ensemble predictions\n",
    "        all_targets.append(target_data.cpu().numpy())\n",
    "\n",
    "    # Concatenate across batches\n",
    "    all_preds = np.concatenate(all_preds, axis=1)  # [E, total_samples, ...]\n",
    "    all_targets = np.concatenate(all_targets, axis=0)  # [total_samples, ...]\n",
    "\n",
    "    print('Shape of all_preds:', all_preds.shape)\n",
    "\n",
    "    return all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803af3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all_preds: (20, 1000, 1733, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get ensemble predictions on test set\n",
    "ensemble_preds, all_targets = get_ensemble_predictions(ensemble, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278d5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and stddev across ensemble members\n",
    "mean_preds = np.mean(ensemble_preds, axis=0)  # [total_samples, ...]\n",
    "stddev_preds = np.std(ensemble_preds, axis=0)  # [total_samples, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d9b6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse scaling the predictions\n",
    "mean_preds_rescaled = scaler.inverse_transform(mean_preds)\n",
    "stddev_preds_rescaled = scaler.inverse_transform(stddev_preds)\n",
    "all_targets_rescaled = scaler.inverse_transform(all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f69fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean relative L2 error (channel 0): 0.0846\n",
      "Mean relative L2 error (channel 1): 0.0030\n",
      "Mean relative L2 error (channel 2): 0.0486\n"
     ]
    }
   ],
   "source": [
    "# compute mean relative l2 error per output channel\n",
    "mean_l2_0 = np.mean(np.linalg.norm(mean_preds_rescaled[..., 0] - all_targets_rescaled[..., 0], axis=1) / np.linalg.norm(all_targets_rescaled[..., 0], axis=1))\n",
    "mean_l2_1 = np.mean(np.linalg.norm(mean_preds_rescaled[..., 1] - all_targets_rescaled[..., 1], axis=1) / np.linalg.norm(all_targets_rescaled[..., 1], axis=1))\n",
    "mean_l2_2 = np.mean(np.linalg.norm(mean_preds_rescaled[..., 2] - all_targets_rescaled[..., 2], axis=1) / np.linalg.norm(all_targets_rescaled[..., 2], axis=1))\n",
    "print(f\"Mean relative L2 error (channel 0): {mean_l2_0:.4f}\")\n",
    "print(f\"Mean relative L2 error (channel 1): {mean_l2_1:.4f}\")\n",
    "print(f\"Mean relative L2 error (channel 2): {mean_l2_2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch-env]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
